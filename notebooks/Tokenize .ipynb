{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = '\\n\\nGB: Shell fabric1:100% polyester\\nrecycled\\n\\nLining:100% polyester recycled\\nPadding: 100% recycled content\\nNL: Bovenstoft: 100% polyester\\ngerecyciede\\n\\nVoering: 100% polyester serecyelade\\nVulling: 100% geracyclede inhoud\\n\\nDE: Oberstofft: 100% Polyester reeyveett\\nFutter: 100% Polyester recyceit\\nWattierung: 100% recycelt Inhalt\\n\\nFR: Etoffe extéricuret: 100%\\npolyester recycle\\n\\nDoublura: 100% polyester recycle\\nRemplissage: 100% recyclé content\\n\\n——_- —-\\n\\n \\n\\n \\n\\x0c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens = word_tokenize(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GB',\n",
       " ':',\n",
       " 'Shell',\n",
       " 'fabric1:100',\n",
       " '%',\n",
       " 'polyester',\n",
       " 'recycled',\n",
       " 'Lining:100',\n",
       " '%',\n",
       " 'polyester',\n",
       " 'recycled',\n",
       " 'Padding',\n",
       " ':',\n",
       " '100',\n",
       " '%',\n",
       " 'recycled',\n",
       " 'content',\n",
       " 'NL',\n",
       " ':',\n",
       " 'Bovenstoft',\n",
       " ':',\n",
       " '100',\n",
       " '%',\n",
       " 'polyester',\n",
       " 'gerecyciede',\n",
       " 'Voering',\n",
       " ':',\n",
       " '100',\n",
       " '%',\n",
       " 'polyester',\n",
       " 'serecyelade',\n",
       " 'Vulling',\n",
       " ':',\n",
       " '100',\n",
       " '%',\n",
       " 'geracyclede',\n",
       " 'inhoud',\n",
       " 'DE',\n",
       " ':',\n",
       " 'Oberstofft',\n",
       " ':',\n",
       " '100',\n",
       " '%',\n",
       " 'Polyester',\n",
       " 'reeyveett',\n",
       " 'Futter',\n",
       " ':',\n",
       " '100',\n",
       " '%',\n",
       " 'Polyester',\n",
       " 'recyceit',\n",
       " 'Wattierung',\n",
       " ':',\n",
       " '100',\n",
       " '%',\n",
       " 'recycelt',\n",
       " 'Inhalt',\n",
       " 'FR',\n",
       " ':',\n",
       " 'Etoffe',\n",
       " 'extéricuret',\n",
       " ':',\n",
       " '100',\n",
       " '%',\n",
       " 'polyester',\n",
       " 'recycle',\n",
       " 'Doublura',\n",
       " ':',\n",
       " '100',\n",
       " '%',\n",
       " 'polyester',\n",
       " 'recycle',\n",
       " 'Remplissage',\n",
       " ':',\n",
       " '100',\n",
       " '%',\n",
       " 'recyclé',\n",
       " 'content',\n",
       " '——_-',\n",
       " '—-']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for string in word_tokens:\n",
    "    for punctuation in punctuations:\n",
    "        text = string.replace(punctuation, '') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'—-'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [''.join(x for x in par if x not in punctuations) for par in word_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GB',\n",
       " '',\n",
       " 'Shell',\n",
       " 'fabric1100',\n",
       " '',\n",
       " 'polyester',\n",
       " 'recycled',\n",
       " 'Lining100',\n",
       " '',\n",
       " 'polyester',\n",
       " 'recycled',\n",
       " 'Padding',\n",
       " '',\n",
       " '100',\n",
       " '',\n",
       " 'recycled',\n",
       " 'content',\n",
       " 'NL',\n",
       " '',\n",
       " 'Bovenstoft',\n",
       " '',\n",
       " '100',\n",
       " '',\n",
       " 'polyester',\n",
       " 'gerecyciede',\n",
       " 'Voering',\n",
       " '',\n",
       " '100',\n",
       " '',\n",
       " 'polyester',\n",
       " 'serecyelade',\n",
       " 'Vulling',\n",
       " '',\n",
       " '100',\n",
       " '',\n",
       " 'geracyclede',\n",
       " 'inhoud',\n",
       " 'DE',\n",
       " '',\n",
       " 'Oberstofft',\n",
       " '',\n",
       " '100',\n",
       " '',\n",
       " 'Polyester',\n",
       " 'reeyveett',\n",
       " 'Futter',\n",
       " '',\n",
       " '100',\n",
       " '',\n",
       " 'Polyester',\n",
       " 'recyceit',\n",
       " 'Wattierung',\n",
       " '',\n",
       " '100',\n",
       " '',\n",
       " 'recycelt',\n",
       " 'Inhalt',\n",
       " 'FR',\n",
       " '',\n",
       " 'Etoffe',\n",
       " 'extéricuret',\n",
       " '',\n",
       " '100',\n",
       " '',\n",
       " 'polyester',\n",
       " 'recycle',\n",
       " 'Doublura',\n",
       " '',\n",
       " '100',\n",
       " '',\n",
       " 'polyester',\n",
       " 'recycle',\n",
       " 'Remplissage',\n",
       " '',\n",
       " '100',\n",
       " '',\n",
       " 'recyclé',\n",
       " 'content',\n",
       " '——',\n",
       " '—']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove(list): \n",
    "    list = [''.join(x for x in i if x.isalpha()) for i in list] \n",
    "              \n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GB',\n",
       " '',\n",
       " 'Shell',\n",
       " 'fabric',\n",
       " '',\n",
       " 'polyester',\n",
       " 'recycled',\n",
       " 'Lining',\n",
       " '',\n",
       " 'polyester',\n",
       " 'recycled',\n",
       " 'Padding',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'recycled',\n",
       " 'content',\n",
       " 'NL',\n",
       " '',\n",
       " 'Bovenstoft',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'polyester',\n",
       " 'gerecyciede',\n",
       " 'Voering',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'polyester',\n",
       " 'serecyelade',\n",
       " 'Vulling',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'geracyclede',\n",
       " 'inhoud',\n",
       " 'DE',\n",
       " '',\n",
       " 'Oberstofft',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Polyester',\n",
       " 'reeyveett',\n",
       " 'Futter',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Polyester',\n",
       " 'recyceit',\n",
       " 'Wattierung',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'recycelt',\n",
       " 'Inhalt',\n",
       " 'FR',\n",
       " '',\n",
       " 'Etoffe',\n",
       " 'extéricuret',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'polyester',\n",
       " 'recycle',\n",
       " 'Doublura',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'polyester',\n",
       " 'recycle',\n",
       " 'Remplissage',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'recyclé',\n",
       " 'content',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = ' '.join(x).split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GB',\n",
       " 'Shell',\n",
       " 'fabric1100',\n",
       " 'polyester',\n",
       " 'recycled',\n",
       " 'Lining100',\n",
       " 'polyester',\n",
       " 'recycled',\n",
       " 'Padding',\n",
       " '100',\n",
       " 'recycled',\n",
       " 'content',\n",
       " 'NL',\n",
       " 'Bovenstoft',\n",
       " '100',\n",
       " 'polyester',\n",
       " 'gerecyciede',\n",
       " 'Voering',\n",
       " '100',\n",
       " 'polyester',\n",
       " 'serecyelade',\n",
       " 'Vulling',\n",
       " '100',\n",
       " 'geracyclede',\n",
       " 'inhoud',\n",
       " 'DE',\n",
       " 'Oberstofft',\n",
       " '100',\n",
       " 'Polyester',\n",
       " 'reeyveett',\n",
       " 'Futter',\n",
       " '100',\n",
       " 'Polyester',\n",
       " 'recyceit',\n",
       " 'Wattierung',\n",
       " '100',\n",
       " 'recycelt',\n",
       " 'Inhalt',\n",
       " 'FR',\n",
       " 'Etoffe',\n",
       " 'extéricuret',\n",
       " '100',\n",
       " 'polyester',\n",
       " 'recycle',\n",
       " 'Doublura',\n",
       " '100',\n",
       " 'polyester',\n",
       " 'recycle',\n",
       " 'Remplissage',\n",
       " '100',\n",
       " 'recyclé',\n",
       " 'content',\n",
       " '——',\n",
       " '—']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL FUNCTION FOR A CLEAN LIST OF STRINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def clean_string(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    punctuations = string.punctuation\n",
    "    clean_string = [''.join(x for x in par if x not in punctuations) for par in word_tokens]\n",
    "    lower_string = [element.lower() for element in clean_string] \n",
    "    clean_string2 = [''.join(x for x in i if x.isalpha()) for i in lower_string] \n",
    "    clean_string_final = ' '.join(clean_string2).split() \n",
    "              \n",
    "    return clean_string_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import string\n",
    "clean = clean_string(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.tokenize import RegexpTokenizer\n",
    "#import re\n",
    "#tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#tokenizer.tokenize(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gb',\n",
       " 'shell',\n",
       " 'fabric',\n",
       " 'polyester',\n",
       " 'recycled',\n",
       " 'lining',\n",
       " 'polyester',\n",
       " 'recycled',\n",
       " 'padding',\n",
       " 'recycled',\n",
       " 'content',\n",
       " 'nl',\n",
       " 'bovenstoft',\n",
       " 'polyester',\n",
       " 'gerecyciede',\n",
       " 'voering',\n",
       " 'polyester',\n",
       " 'serecyelade',\n",
       " 'vulling',\n",
       " 'geracyclede',\n",
       " 'inhoud',\n",
       " 'de',\n",
       " 'oberstofft',\n",
       " 'polyester',\n",
       " 'reeyveett',\n",
       " 'futter',\n",
       " 'polyester',\n",
       " 'recyceit',\n",
       " 'wattierung',\n",
       " 'recycelt',\n",
       " 'inhalt',\n",
       " 'fr',\n",
       " 'etoffe',\n",
       " 'extéricuret',\n",
       " 'polyester',\n",
       " 'recycle',\n",
       " 'doublura',\n",
       " 'polyester',\n",
       " 'recycle',\n",
       " 'remplissage',\n",
       " 'recyclé',\n",
       " 'content']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying typo functions(not the correct one!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean2 = 'Waist S@rstpilio riot ©brologiatgigaaters or Soc dry Piai:torstane Rinse and hang: Sey Immediat,J0% GOTON | GOTOR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import string\n",
    "clean3 = clean_string(clean2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean3_join = ' '.join(clean3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'waist s rstpilio riot brologiatgigaaters or soc dry piai torstane rinse and hang sey immediat j goton gotor'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean3_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cotton\n"
     ]
    }
   ],
   "source": [
    "words = ['cotton'];\n",
    "def get_exact_words(input_str):\n",
    "    exact_words = difflib.get_close_matches(input_str,words,n=1,cutoff=0.7)\n",
    "    if len(exact_words)>0:\n",
    "        return exact_words[0]\n",
    "    else:\n",
    "        return input_str\n",
    "\n",
    "string = \"goton\"\n",
    "string = string.split(' ')\n",
    "exact = [get_exact_words(word) for word in string]\n",
    "\n",
    "exact = ' '.join(exact)\n",
    "print(exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['cotton'];\n",
    "def get_exact_words(input_str):\n",
    "    exact_words = difflib.get_close_matches(input_str,words,n=1,cutoff=0.7)\n",
    "    if len(exact_words)>0:\n",
    "        return exact_words[0]\n",
    "    else:\n",
    "        return input_str\n",
    "    \n",
    "def loop(input_str):\n",
    "    for string in input_str:\n",
    "    #string = words.split(' ')\n",
    "        exact = [get_exact_words(word) for word in string]\n",
    "\n",
    "        #exact = ' '.join(exact)\n",
    "    return exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['r']\n"
     ]
    }
   ],
   "source": [
    "print(loop(clean3_join))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n",
      "cotton\n",
      "{'totton', 'cotton', 'gorton', 'otton', 'botton', 'potton', 'wotton', 'gotten'}\n"
     ]
    }
   ],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "\n",
    "# find those words that may be misspelled\n",
    "for word in clean:\n",
    "    misspelled = spell.unknown(['GOTTON'])\n",
    "\n",
    "    for word in misspelled:\n",
    "    # Get the one `most likely` answer\n",
    "        print(spell.correction(word))\n",
    "\n",
    "    # Get a list of `likely` options\n",
    "        print(spell.candidates(word))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enchant\n",
    "d = enchant.request_pwl_dict(\"mywords.txt\")\n",
    "d.check('p')\n",
    "False\n",
    "d.suggest(\"Helo\")\n",
    "['He lo', 'He-lo', 'Hello', 'Helot', 'Help', 'Halo', 'Hell', 'Held', 'Helm', 'Hero', \"He'll\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pokyester\n"
     ]
    }
   ],
   "source": [
    "import random # random typos\n",
    "\n",
    "message = 'polyester'\n",
    "\n",
    "# convert the message to a list of characters\n",
    "message = list(message)\n",
    "\n",
    "typo_prob = 0.1 # percent (out of 1.0) of characters to become typos\n",
    "\n",
    "# the number of characters that will be typos\n",
    "n_chars_to_flip = round(len(message) * typo_prob)\n",
    "# is a letter capitalized?\n",
    "capitalization = [False] * len(message)\n",
    "# make all characters lowercase & record uppercase\n",
    "for i in range(len(message)):\n",
    "    capitalization[i] = message[i].isupper()\n",
    "    message[i] = message[i].lower()\n",
    "\n",
    "# list of characters that will be flipped\n",
    "pos_to_flip = []\n",
    "for i in range(n_chars_to_flip):\n",
    "    pos_to_flip.append(random.randint(0, len(message) - 1))\n",
    "\n",
    "# dictionary... for each letter list of letters\n",
    "# nearby on the keyboard\n",
    "nearbykeys = {\n",
    "    'a': ['q','w','s','x','z'],\n",
    "    'b': ['v','g','h','n'],\n",
    "    'c': ['x','d','f','v'],\n",
    "    'd': ['s','e','r','f','c','x'],\n",
    "    'e': ['w','s','d','r'],\n",
    "    'f': ['d','r','t','g','v','c'],\n",
    "    'g': ['f','t','y','h','b','v'],\n",
    "    'h': ['g','y','u','j','n','b'],\n",
    "    'i': ['u','j','k','o'],\n",
    "    'j': ['h','u','i','k','n','m'],\n",
    "    'k': ['j','i','o','l','m'],\n",
    "    'l': ['k','o','p'],\n",
    "    'm': ['n','j','k','l'],\n",
    "    'n': ['b','h','j','m'],\n",
    "    'o': ['i','k','l','p'],\n",
    "    'p': ['o','l'],\n",
    "    'q': ['w','a','s'],\n",
    "    'r': ['e','d','f','t'],\n",
    "    's': ['w','e','d','x','z','a'],\n",
    "    't': ['r','f','g','y'],\n",
    "    'u': ['y','h','j','i'],\n",
    "    'v': ['c','f','g','v','b'],\n",
    "    'w': ['q','a','s','e'],\n",
    "    'x': ['z','s','d','c'],\n",
    "    'y': ['t','g','h','u'],\n",
    "    'z': ['a','s','x'],\n",
    "    ' ': ['c','v','b','n','m']\n",
    "}\n",
    "\n",
    "# insert typos\n",
    "for pos in pos_to_flip:\n",
    "    # try-except in case of special characters\n",
    "    try:\n",
    "        typo_arrays = nearbykeys[message[pos]]\n",
    "        message[pos] = random.choice(typo_arrays)\n",
    "    except:\n",
    "        break\n",
    "\n",
    "# recombine the message into a string\n",
    "message = ''.join(message)\n",
    "\n",
    "# show the message in the console\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
